{
    "en":{

        "sub_title":"Time series Forecasting",

        "expander_upload_arrange":"Uplaod file and Decide date scope",

        "decide_date_column":"Decide date column",
        "decide_pred_column":"Decide prediction column",

        "invalid_format":"Invalid format.",

        "train_data_arrange":"Decide train data scope",
        "val_data_arrange":"The test data range is specified from the end to the beginning of the training data.",
        "pred_data_arrange":"The additional predictive data provides 10% of the range of the test data.",

        "date_column_not_exist_select_column":"The range of dates doesn't exist, or please set the column correctly",

        "upload_train_csv":"Please upload a csv",

        "upload_info":"if you uploads file, you can choice column and decide data scope",

        "expander_train_prediction":"Training Model and prediction",

        "HP_learning_rate":"Learning rate :question:",
        "HP_epoch":"Epoch :question:",
        "HP_window_size":"Window size :question:",
        "HP_horizon_factor":"Horizion Factor :question:",

        "ex_learning_rate":"Learning rate refers to the amount or steps trained in Mahcine learning \n\nLearning rate baseline value \nHow you set the value of the learning rate determines the ML results. Only by setting the optimal learning rate will you get the results you want in the end. If the value of the learning rate is not appropriate, overflow can also occur. In short, if the learning rate is too large, you won't be able to reduce the errors that occur during training. On the other hand, too low a learning rate is not a good thing. If the learning rate is too low, the ML process will take too long and the number of error values to validate will be too high, causing the machine learning to stall. In short, a high learning rate will produce faster results, but may not produce enough error values or may cause overflows; conversely, a low learning rate will produce slower results and may produce too many error values, causing the execution process to stall. Therefore, it's important to find the right learning rate value.\n\nLearning rate default value \nIn general, you can try values like 0.1, 0.01, 0.001, etc.",
        "ex_epoch":"Epoch refers to the number of times the entire dataset was trained.\n\nEpoch example \nLet's return to our example of a person studying from a question book. An epoch is the number of times you've completed all of the questions in a set from start to finish, including grading. Some people have solved the entire book once, while others have solved it 3, 5, or even 10 times. An epoch is how many times you've solved a book of questions like this. This means that if you have 10 epochs, you have trained your model on training dataset A 10 times.\n\nEpoch range \nAs you increase the number of epochs, the probability of finding a good parameter increases (i.e., the loss value goes down) because you are training with different random weights. However, if you increase the epoch too much, you increase the likelihood that it will overfit that training dataset and make poor predictions on other data.",
        "ex_window_size":"Window size is a parameter that determines how much of the input data is used. The window size can have a direct impact on the performance of the forecasting model and should be well chosen. \n\nwindow size example \nFor example, suppose you want to predict the price of a stock on a daily basis. If you set the window size to 30, you can use the last 30 days of stock price data as input to your model to predict the next day's stock price. By setting the window size to 30, the model learns patterns such as trends, seasonality, and volatility over the last 30 days to make predictions. \n\nwindow size range \nThe window size should be adjusted based on the nature of the data and the time horizon you want to predict. If you choose a window size that is too small, the model may not capture enough information; conversely, if you choose a window size that is too large, the model may only focus on long-term patterns in the past and miss transient variability. Therefore, it is important to choose the right window size for your problem.",
        "ex_horizon_factor":"The horizon factor is a parameter that indicates the time range you want to predict. Predictive models are used to predict future values based on historical data, and the horizon factor determines how far in the future you want to predict values. \n\nhorizon factor example \nFor example, let's say you want to predict the price of a stock on a daily basis. If you set the horizon factor to 5, the model will try to predict the stock price five days from now, meaning that the model will sequentially predict the stock price on days 1, 2, 3, 4, and 5 based on the given input data. As another example, suppose you want to forecast monthly sales. If you set the horizon factor to 3, the model will try to predict sales three months from now. This means that the model will sequentially predict sales for the next month, the month after that, and the month after that based on the given input data. \n\nhorizon factor range \nThe horizon factor is an important factor that affects the performance of a forecasting model. Predicting farther into the future becomes more difficult, and forecast errors are likely to accumulate. Therefore, the HORIZON FACTOR should be used to balance the time span you want to predict with forecast accuracy.",

        "explanation_title":"Explanation",
        "explanation_text":"if you click hyperparameter name or ?, you can see hyperparameter explanation",
        
        "training_validation_model_button":"Model train and test",
        "training_model_spinner":"Model is training. Don't click other button",
        "prediction_model_button":"Prediction",

        "time_series_forecasting":"Time series forecasting result",

        "pred_graph" : "if training, validation and prediction is progressed, you can see result graph",

        "pred_after_down": "Downloadable model when forecasting!",

        "model_download":"Download Model "

        }
}
