{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce817bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:21.307812Z",
     "start_time": "2023-05-30T00:17:21.306455Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://hoit1302.tistory.com/159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ccc1db6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:22.573618Z",
     "start_time": "2023-05-30T00:17:21.308614Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gluonnlp as nlp\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "039f6c03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:22.720349Z",
     "start_time": "2023-05-30T00:17:22.574474Z"
    }
   },
   "outputs": [],
   "source": [
    "from kobert import get_tokenizer\n",
    "from kobert import get_pytorch_kobert_model\n",
    "from kobert_tokenizer import KoBERTTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb48753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:23.364521Z",
     "start_time": "2023-05-30T00:17:22.721082Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers.optimization import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "217a1bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:23.979594Z",
     "start_time": "2023-05-30T00:17:23.365325Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import transformers\n",
    "from transformers import AdamW\n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "import datasets\n",
    "from datasets import load_dataset, load_metric, ClassLabel\n",
    "\n",
    "import huggingface_hub\n",
    "import pyarrow\n",
    "\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray.tune.examples.pbt_transformers.utils import (\n",
    "    download_data,\n",
    "    build_compute_metrics_fn,\n",
    ")\n",
    "\n",
    "from datasets.arrow_dataset import Dataset\n",
    "from datasets.dataset_dict import DatasetDict\n",
    "from typing import TypeVar, Type\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c1c2a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:23.982639Z",
     "start_time": "2023-05-30T00:17:23.980446Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8.1\n",
      "1.11.0\n",
      "0.0.12\n",
      "9.0.0\n",
      "1.9.0+cu111\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import huggingface_hub\n",
    "import pyarrow\n",
    "import torch\n",
    "print(transformers.__version__)\n",
    "print(datasets.__version__)\n",
    "print(huggingface_hub.__version__)\n",
    "print(pyarrow.__version__)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef278791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.005238Z",
     "start_time": "2023-05-30T00:17:23.983277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 1\n",
      "device 0 capability (8, 6)\n",
      "device 0 name NVIDIA GeForce RTX 3080\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(\"device_count: {}\".format(device_count))\n",
    "    for device_num in range(device_count):\n",
    "        print(\"device {} capability {}\".format(\n",
    "            device_num,\n",
    "            torch.cuda.get_device_capability(device_num)))\n",
    "        print(\"device {} name {}\".format(\n",
    "            device_num, \n",
    "            torch.cuda.get_device_name(device_num)))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"no cuda device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc5e7d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.218150Z",
     "start_time": "2023-05-30T00:17:24.006511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\r\n"
     ]
    }
   ],
   "source": [
    "#### The number of CPU cores\n",
    "!grep -c processor /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ccc9f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.241003Z",
     "start_time": "2023-05-30T00:17:24.224260Z"
    }
   },
   "outputs": [],
   "source": [
    "# import bert_functions\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5a2b2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.255752Z",
     "start_time": "2023-05-30T00:17:24.242149Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(dataset: DatasetDict,\n",
    "                  text_column: str,\n",
    "                  label_column: str,\n",
    "                  id_column: str,\n",
    "                  model_name: str,\n",
    "                  train_proportion: float,\n",
    "                  seed: int,\n",
    "                  custom_tokenizer_dir: str = \"my_result\"\n",
    "                  ) -> tuple:\n",
    "    if not isinstance(dataset, DatasetDict):\n",
    "        raise TypeError(f\"Values in `dataset` should be of type `DatasetDict` but got type '{type(dataset)}'\")\n",
    "    \n",
    "    # Select columns to use\n",
    "    print(\"Removing rows with missing value...\")\n",
    "    cols_to_remove = list(dataset['train'].features.keys())\n",
    "    cols_to_remove.remove(id_column)\n",
    "    cols_to_remove.remove(text_column)\n",
    "    cols_to_remove.remove(label_column)\n",
    "    dataset = dataset.remove_columns(cols_to_remove)\n",
    "    if 'text' not in dataset['train'].features.keys():\n",
    "        dataset = dataset.rename_column(text_column, \"text\")\n",
    "    if label_column not in dataset['train'].features.keys():\n",
    "        dataset = dataset.rename_column(label_column, \"label\")\n",
    "    if id_column not in dataset['train'].features.keys():\n",
    "        dataset = dataset.rename_column(id_column, \"id\")\n",
    "     \n",
    "    # Remove NA rows\n",
    "    dataset = dataset.filter(lambda row: pd.notnull(row[\"text\"]))\n",
    "    print(\"Done. (1/4)\")\n",
    "    \n",
    "    # Remove specal characters\n",
    "    print(\"Removing special characters...\")\n",
    "    def remove_sp_fn(dataset):\n",
    "        dataset[\"text\"]=re.sub(r'[^a-z|A-Z|0-9|ㄱ-ㅎ|ㅏ-ㅣ|가-힣| ]+', '', str(dataset[\"text\"]))\n",
    "        return dataset\n",
    "    \n",
    "    dataset = dataset.map(remove_sp_fn)\n",
    "    print(\"Done. (2/4)\")\n",
    "    \n",
    "    # Tokenize\n",
    "    print(\"Tokenining the text column...\")\n",
    "    tokenizer = KoBERTTokenizer.from_pretrained(model_name, truncation_side = 'left')\n",
    "    def tokenize_fn(dataset):\n",
    "        tokenized_batch = tokenizer(dataset[\"text\"], truncation=True, padding=\"max_length\", max_length=24)\n",
    "        return tokenized_batch\n",
    "    \n",
    "    dataset = dataset.map(tokenize_fn, batched=True)\n",
    "    tokenizer.save_pretrained(custom_tokenizer_dir)\n",
    "    print(\"Done. (3/4)\")\n",
    "    \n",
    "    # train-evaluation-test split\n",
    "    print(\"Spliting train-evaluation-test set...\")\n",
    "    train_dataset = dataset[\"train\"].shuffle(seed=seed).select(range(0,math.floor(len(dataset[\"train\"])*train_proportion)))\n",
    "    eval_dataset = dataset[\"train\"].shuffle(seed=seed).select(range(math.floor(len(dataset[\"train\"])*train_proportion), len(dataset[\"train\"])))\n",
    "    test_dataset = dataset[\"test\"]\n",
    "    print(\"Done. (4/4)\")\n",
    "    \n",
    "    return train_dataset, eval_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c3fb593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.271921Z",
     "start_time": "2023-05-30T00:17:24.257041Z"
    }
   },
   "outputs": [],
   "source": [
    "def modeling(train_dataset: Dataset,\n",
    "             eval_dataset: Dataset,\n",
    "             num_labels: int, \n",
    "             model_name: str,\n",
    "             num_gpus: int,\n",
    "             num_cpus: int,\n",
    "             seed: int,\n",
    "             output_dir: str = './output',\n",
    "             logging_dir: str = \"./logs\",\n",
    "             do_hpo: bool = False,\n",
    "             std: float = 0.1,\n",
    "             n_trials: int = 5,\n",
    "             patience: int = 3,\n",
    "             hpo_result_dir: str = \"./hpo-results\",\n",
    "             hpo_result_dir_subfolder_name: str = 'tune_transformer_pbt',\n",
    "             custom_model_dir: str = \"my_result\"\n",
    "             ) -> Type[Trainer]:\n",
    "    if not isinstance(train_dataset, Dataset):\n",
    "        raise TypeError(f\"Values in `train_dataset` should be of type `Dataset` but got type '{type(train_dataset)}'\")\n",
    "    elif not isinstance(eval_dataset, Dataset):\n",
    "        raise TypeError(f\"Values in `eval_dataset` should be of type `Dataset` but got type '{type(eval_dataset)}'\")\n",
    "        \n",
    "    train_dataset = train_dataset.remove_columns('id')\n",
    "    eval_dataset = eval_dataset.remove_columns('id')\n",
    "        \n",
    "    # Load the model \n",
    "    def _model_init():\n",
    "        return AutoModelForSequenceClassification.from_pretrained(\n",
    "            model_name,\n",
    "            num_labels = 7,\n",
    "            output_attentions = False,\n",
    "            output_hidden_states = False\n",
    "            )\n",
    "\n",
    "    # Define metrics to use for evaluation\n",
    "    def _compute_metrics(eval_pred):\n",
    "#         metric1 = load_metric(\"accuracy\")\n",
    "#         metric2 = load_metric(\"f1\")\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "#         accuracy = metric1.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "#         f1 = metric2.compute(predictions=predictions, references=labels)[\"f1\"]\n",
    "        f1_weighted = f1_score(labels, predictions, average = 'weighted')\n",
    "        acc_weighted = accuracy_score(labels, predictions)\n",
    "        return {\"acc_weighted\": acc_weighted, \"f1_weighted\": f1_weighted, \"objective\": acc_weighted + f1_weighted}\n",
    "\n",
    "    # Default: batch size = 32, evaluate every 50 steps\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        do_train=True,\n",
    "        do_eval=True,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=64,\n",
    "        gradient_accumulation_steps=4,\n",
    "        learning_rate=2e-5, # config\n",
    "        weight_decay=0.1, # config\n",
    "        adam_beta1=0.9, # config\n",
    "        adam_beta2=0.9, # config\n",
    "        adam_epsilon=1.5e-06, # config\n",
    "        num_train_epochs=20, # config\n",
    "        max_steps=-1,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        warmup_ratio=0.1,  # config\n",
    "        warmup_steps=0,\n",
    "        logging_dir=logging_dir,\n",
    "        save_strategy=\"steps\",\n",
    "        no_cuda=num_gpus <= 0, \n",
    "        seed=seed,  # config\n",
    "#         bf16=False, # Need torch>=1.10, Ampere GPU with cuda>=11.0\n",
    "        fp16=True,\n",
    "#         tf32=True, \n",
    "        eval_steps = 50,\n",
    "        load_best_model_at_end=True,\n",
    "        greater_is_better=True,\n",
    "        metric_for_best_model=\"objective\", # f1 + acc\n",
    "        report_to=\"none\",\n",
    "        skip_memory_metrics=True,\n",
    "#         gradient_checkpointing=True\n",
    "        )\n",
    "    \n",
    "    # Calculate class weights\n",
    "    train_labels = np.array(train_dataset[\"label\"])\n",
    "    class_weights = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "    weights = torch.tensor(class_weights, dtype = torch.float)\n",
    "    \n",
    "    # Define device\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else: \n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    # Customize trainer class to apply class weights\n",
    "    class CustomTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.get(\"labels\")\n",
    "            # forward pass\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get(\"logits\")\n",
    "            # compute custom loss\n",
    "            weight = weights.to(device)\n",
    "            loss_fct = torch.nn.CrossEntropyLoss(weight=weight)\n",
    "            loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    trainer = CustomTrainer(\n",
    "        model_init=_model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        compute_metrics=_compute_metrics,\n",
    "        )\n",
    "    \n",
    "    if do_hpo == True:\n",
    "    \n",
    "        # Initialize Ray\n",
    "        ray.shutdown()\n",
    "        ray.init(log_to_driver=False, ignore_reinit_error=True, num_cpus=num_cpus, num_gpus=num_gpus, include_dashboard=False)\n",
    "\n",
    "        # Fix batch_size in each trial\n",
    "        def _hp_space(trial):\n",
    "            return {\n",
    "                \"per_device_eval_batch_size\": 32,\n",
    "                \"per_device_train_batch_size\": 64,\n",
    "                \"max_steps\": -1,\n",
    "                \"weight_decay\": tune.uniform(0.0, 0.1),\n",
    "                \"learning_rate\": tune.uniform(1e-6, 1e-4),\n",
    "                \"warmup_ratio\": tune.uniform(0.0, 0.1),\n",
    "                \"adam_beta1\": tune.loguniform(0.97, 0.99),\n",
    "                \"adam_beta2\": tune.loguniform(0.97, 0.99),\n",
    "                \"adam_epsilon\": tune.loguniform(1e-9, 1e-7),\n",
    "                \"max_grad_norm\": tune.uniform(0.0, 5.0),\n",
    "            }\n",
    "\n",
    "        def explore(config):\n",
    "            # Define your hyperparameters' ranges.\n",
    "            bounds = {\n",
    "                \"weight_decay\": (0.0, 0.1),\n",
    "                \"learning_rate\": (1e-6, 1e-4),\n",
    "                \"warmup_ratio\": (0.0, 0.1),\n",
    "                \"adam_beta1\": (0.97, 0.99),\n",
    "                \"adam_beta2\": (0.97, 0.99),\n",
    "                \"adam_epsilon\": (1e-9, 1e-7),\n",
    "                \"max_grad_norm\": (0.0, 5.0),\n",
    "            }\n",
    "\n",
    "            factor = 0.2  # The perturbation factor.\n",
    "\n",
    "            for hyperparam, (lower, upper) in bounds.items():\n",
    "                value = config[hyperparam]\n",
    "\n",
    "                if np.random.uniform() > 0.5:  # Apply perturbation.\n",
    "                    scale_factor = 1 + factor if np.random.uniform() > 0.5 else 1 - factor\n",
    "                    value *= scale_factor\n",
    "                else:  # Resample.\n",
    "                    value = np.random.uniform(lower, upper)\n",
    "\n",
    "                # Clip to ensure it's within bounds.\n",
    "                config[hyperparam] = np.clip(value, lower, upper)\n",
    "            \n",
    "            return config\n",
    "\n",
    "        # PBT schduler\n",
    "        scheduler = PopulationBasedTraining(\n",
    "            time_attr=\"training_iteration\",\n",
    "            metric=\"objective\",\n",
    "            mode=\"max\",\n",
    "            perturbation_interval=1,\n",
    "            custom_explore_fn=explore\n",
    "        )\n",
    "\n",
    "        # Define columns to report\n",
    "        reporter = CLIReporter(\n",
    "            parameter_columns={\n",
    "                \"learning_rate\": \"lr\",\n",
    "                \"warmup_ratio\" : \"warmup_ratio\",\n",
    "                \"max_grad_norm\" : \"max_grad_norm\"\n",
    "            },\n",
    "            metric_columns=[\"eval_acc_weighted\", \"eval_f1_weighted\", \"eval_objective\", \"eval_loss\", \"epoch\", \"training_iteration\"]\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        stopper = tune.stopper.ExperimentPlateauStopper(metric=\"objective\", \n",
    "                                                        std=std,\n",
    "                                                        top=n_trials,\n",
    "                                                        mode=\"max\",\n",
    "                                                        patience=patience\n",
    "                                                        )\n",
    "\n",
    "        # HPO\n",
    "        hpo_result = trainer.hyperparameter_search(\n",
    "            hp_space = _hp_space,\n",
    "            direction = \"maximize\",\n",
    "            backend=\"ray\",\n",
    "            reuse_actors = True,\n",
    "            n_trials=n_trials,\n",
    "            resources_per_trial={\"cpu\": num_cpus, \"gpu\": num_gpus},\n",
    "            scheduler=scheduler,\n",
    "            keep_checkpoints_num=1,\n",
    "            checkpoint_score_attr=\"training_iteration\",\n",
    "            stop=stopper,\n",
    "            progress_reporter=reporter,\n",
    "            local_dir=hpo_result_dir,\n",
    "            name=hpo_result_dir_subfolder_name,\n",
    "            log_to_file=True,\n",
    "        )\n",
    "        for n, v in hpo_result.hyperparameters.items():\n",
    "            setattr(trainer.args, n, v)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6244cc5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.287188Z",
     "start_time": "2023-05-30T00:17:24.272571Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluation(trainer: Trainer, \n",
    "               eval_dataset: Dataset,\n",
    "               text_column_name: str\n",
    "               ) -> pd.DataFrame:\n",
    "    if not isinstance(eval_dataset, Dataset):\n",
    "        raise TypeError(f\"Values in `eval_dataset` should be of type `Dataset` but got type '{type(eval_dataset)}'\")\n",
    "        \n",
    "    # id column\n",
    "    eval_dataset_id = eval_dataset\n",
    "    eval_dataset_id = eval_dataset_id.remove_columns(['text', 'label', 'input_ids', 'attention_mask', 'token_type_ids'])\n",
    "    eval_dataset_id = eval_dataset_id.to_pandas()\n",
    "    \n",
    "    # Add ID to the result after performing prediction with eval data\n",
    "    eval_dataset = eval_dataset.remove_columns('id')\n",
    "    eval_pred_result = trainer.predict(test_dataset=eval_dataset)\n",
    "    \n",
    "    # prediction result\n",
    "    pred_df = pd.DataFrame(eval_pred_result.predictions)\n",
    "    pred_df.columns = [f'{text_column_name}_pred_0', f'{text_column_name}_pred_1', f'{text_column_name}_pred_2', f'{text_column_name}_pred_3', f'{text_column_name}_pred_4', f'{text_column_name}_pred_5', f'{text_column_name}_pred_6']\n",
    "    \n",
    "    # classification result\n",
    "    cls_label = list(eval_pred_result.label_ids)\n",
    "    cls_pred = list(map(lambda x: x.index(max(x)), eval_pred_result.predictions.tolist()))\n",
    "    \n",
    "    eval_result_df = pd.concat([pd.DataFrame(eval_dataset_id),\n",
    "                                pd.DataFrame(eval_dataset['text']), \n",
    "                                pd.DataFrame(pred_df), \n",
    "                                pd.DataFrame(cls_label),\n",
    "                                pd.DataFrame(cls_pred)],\n",
    "                               axis=1)\n",
    "                               \n",
    "    eval_result_df.columns = ['id', 'text', f'{text_column_name}_pred_0', f'{text_column_name}_pred_1', f'{text_column_name}_pred_2', f'{text_column_name}_pred_3', f'{text_column_name}_pred_4', f'{text_column_name}_pred_5', f'{text_column_name}_pred_6', 'label', 'pred']\n",
    "    \n",
    "    return eval_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73acc26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.303129Z",
     "start_time": "2023-05-30T00:17:24.288431Z"
    }
   },
   "outputs": [],
   "source": [
    "# hardware\n",
    "num_cpus = 16\n",
    "num_gpus = 1\n",
    "\n",
    "# model\n",
    "model_name = \"skt/kobert-base-v1\"\n",
    "\n",
    "# data\n",
    "text_column = 'text' \n",
    "label_column = 'label'\n",
    "id_column = 'id'\n",
    "custom_dir = \"SA_model\"\n",
    "\n",
    "# process\n",
    "seed = 9572\n",
    "train_proportion = 0.8\n",
    "do_hpo = True\n",
    "# If you want to search best hyperparameters using ray tune(do_hpo = True), parameters below should be set for ealry sttoping\n",
    "n_trials = 5 # 새로운 experiment 수행 시마다 n_trials개의 최고 성능을 가진 experiment을 유지\n",
    "std = 0.01 # metric의 표준 편차. metric의 표준편차가 std보다 작아지면, n_trials 개의 최고 성능을 가진 결과를 유지하면서 patience번째 epoch에서 실험을 중지\n",
    "patience = 5 # metric이 std보다 작은 상태로 patience epoch 동안 개선되지 않으면 Stopper 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b794d953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.391714Z",
     "start_time": "2023-05-30T00:17:24.305260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>ㅅ  두둠칫            두둠칫  |   | | |    | |     L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>우울</td>\n",
       "      <td>부모님께짐만되는거 같아요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>분노</td>\n",
       "      <td>그 옛날 액티브 엑스 찬양하던 새끼들 어디갔어</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>두려움</td>\n",
       "      <td>밖에나가는게 좀 무섭다라고할까요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>분노</td>\n",
       "      <td>욕 밖에 안나온다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54812</th>\n",
       "      <td>54876</td>\n",
       "      <td>분노</td>\n",
       "      <td>힘있고 돈많으면 굽실굽실 힘없고 가난하면 으쓱으쓱</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54813</th>\n",
       "      <td>54877</td>\n",
       "      <td>분노</td>\n",
       "      <td>힘좀세졋다고 천조국한테까지 깝치지만 현실은 힘만센 속좁은 찌질이</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54814</th>\n",
       "      <td>54878</td>\n",
       "      <td>두려움</td>\n",
       "      <td>힘주면 옆에 뽝 서는게 뭐죠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54815</th>\n",
       "      <td>54879</td>\n",
       "      <td>우울</td>\n",
       "      <td>힝 불타는 금요일인데 맥주한잔을 못하다니ㅠㅠㅜ 감기 주거버렷ㅠㅜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54816</th>\n",
       "      <td>54880</td>\n",
       "      <td>분노</td>\n",
       "      <td>힝상 노력을 하고자 하는 생각은 있으나 생각에 그치지 않는다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54817 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id label                                               text\n",
       "0          1    기쁨      ㅅ  두둠칫            두둠칫  |   | | |    | |     L\n",
       "1          2    우울                                      부모님께짐만되는거 같아요\n",
       "2          3    분노                          그 옛날 액티브 엑스 찬양하던 새끼들 어디갔어\n",
       "3          4   두려움                                 밖에나가는게 좀 무섭다라고할까요 \n",
       "4          5    분노                                          욕 밖에 안나온다\n",
       "...      ...   ...                                                ...\n",
       "54812  54876    분노                        힘있고 돈많으면 굽실굽실 힘없고 가난하면 으쓱으쓱\n",
       "54813  54877    분노                힘좀세졋다고 천조국한테까지 깝치지만 현실은 힘만센 속좁은 찌질이\n",
       "54814  54878   두려움                                    힘주면 옆에 뽝 서는게 뭐죠\n",
       "54815  54879    우울                힝 불타는 금요일인데 맥주한잔을 못하다니ㅠㅠㅜ 감기 주거버렷ㅠㅜ\n",
       "54816  54880    분노                  힝상 노력을 하고자 하는 생각은 있으나 생각에 그치지 않는다\n",
       "\n",
       "[54817 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_name = \"sent_merge\" \n",
    "\n",
    "data_dir = f'./{data_name}.csv' # your local raw data dir\n",
    "data = pd.read_csv(data_dir)\n",
    "data.rename(columns = {'Unnamed: 0':'id'}, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66d490c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.408226Z",
     "start_time": "2023-05-30T00:17:24.392431Z"
    }
   },
   "outputs": [],
   "source": [
    "data['label'] = data['label'].replace(['기쁨', '우울', '분노', '두려움', '사랑', '놀람', '중립'], [0,1,2,3,4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1b34be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:24.409960Z",
     "start_time": "2023-05-30T00:17:24.408864Z"
    }
   },
   "outputs": [],
   "source": [
    "# y = data.label\n",
    "# X = data.drop('label', axis=1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=seed) # The test set is 20% of the total as default.\n",
    "\n",
    "# train = pd.concat([X_train, y_train], axis=1)\n",
    "# test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# train.to_csv(f'../data_split/{data_name}_train.csv', index=False) # your local splited data dir\n",
    "# test.to_csv(f'../data_split/{data_name}_test.csv', index=False) # your local splited data dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf5c8738",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:25.279125Z",
     "start_time": "2023-05-30T00:17:24.410551Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8e80763ffbac1bee\n",
      "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 43853\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'text', 'label'],\n",
       "        num_rows: 10964\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files={'train': f'../data_split/{data_name}_train.csv',\n",
    "                                          'test': f'../data_split/{data_name}_test.csv'})\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3107435b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:27.178262Z",
     "start_time": "2023-05-30T00:17:25.279792Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-b91a2ee2b4f71682.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-04f2abd210e34614.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-12a6d097444e3a61.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-6983a70bf50cc5be.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with missing value...\n",
      "Done. (1/4)\n",
      "Removing special characters...\n",
      "Done. (2/4)\n",
      "Tokenining the text column...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-93914eeb6b343168.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-fb0ea163b41d3ca7.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-ec0cf316089b6655.arrow\n",
      "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/csv/default-8e80763ffbac1bee/0.0.0/9144e0a4e8435090117cea53e6c7537173ef2304525df4a077c435d8ee7828ff/cache-ec0cf316089b6655.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. (3/4)\n",
      "Spliting train-evaluation-test set...\n",
      "Done. (4/4)\n"
     ]
    }
   ],
   "source": [
    "train_dataset, eval_dataset, test_dataset = preprocessing(dataset = dataset,\n",
    "                                                          text_column = text_column, \n",
    "                                                          label_column = label_column,\n",
    "                                                          id_column = id_column,\n",
    "                                                          model_name = model_name,\n",
    "                                                          train_proportion = train_proportion,\n",
    "                                                          seed = seed,\n",
    "                                                          custom_tokenizer_dir = custom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ffd03a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:27.180289Z",
     "start_time": "2023-05-30T00:17:27.178959Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer = modeling(train_dataset=train_dataset,\n",
    "#                    eval_dataset=eval_dataset,\n",
    "#                    num_labels = 7,\n",
    "#                    model_name=model_name,\n",
    "#                    num_gpus=num_gpus,\n",
    "#                    num_cpus=num_cpus,\n",
    "#                    seed=seed,\n",
    "#                    output_dir='./output',\n",
    "#                    logging_dir=\"./logs\",\n",
    "#                    do_hpo=do_hpo,\n",
    "#                    std = std,\n",
    "#                    n_trials = n_trials,\n",
    "#                    patience = patience,\n",
    "#                    hpo_result_dir = \"./hpo-results\",\n",
    "#                    hpo_result_dir_subfolder_name = 'tune_transformer_pbt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7af29630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:27.190603Z",
     "start_time": "2023-05-30T00:17:27.180881Z"
    }
   },
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9709db03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:17:27.371209Z",
     "start_time": "2023-05-30T00:17:27.191335Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1329d6bee143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save the pretrained model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# # save the pretrained model\n",
    "# trainer.model.save_pretrained(custom_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0141db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:29.609039Z",
     "start_time": "2023-05-30T00:18:27.134191Z"
    }
   },
   "outputs": [],
   "source": [
    "# load model\n",
    "ft_model_path = './SA_model'\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(ft_model_path)\n",
    "trainer = Trainer(model=loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8313449",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:34.683474Z",
     "start_time": "2023-05-30T00:18:29.609812Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 8771\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1097' max='1097' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1097/1097 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>text_pred_0</th>\n",
       "      <th>text_pred_1</th>\n",
       "      <th>text_pred_2</th>\n",
       "      <th>text_pred_3</th>\n",
       "      <th>text_pred_4</th>\n",
       "      <th>text_pred_5</th>\n",
       "      <th>text_pred_6</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13873</td>\n",
       "      <td>누나가 청소 내기를 하자고 했는데 내가 이겼어</td>\n",
       "      <td>5.299185</td>\n",
       "      <td>1.222584</td>\n",
       "      <td>-0.529279</td>\n",
       "      <td>-0.220333</td>\n",
       "      <td>-2.441689</td>\n",
       "      <td>-2.766117</td>\n",
       "      <td>-1.144773</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13586</td>\n",
       "      <td>노후 때문에 부동산 투기하던 친구가 이번에 세금을 많이 물게 됐다고 나한테 말했는데...</td>\n",
       "      <td>-1.710246</td>\n",
       "      <td>4.793097</td>\n",
       "      <td>1.939720</td>\n",
       "      <td>0.995886</td>\n",
       "      <td>-1.486930</td>\n",
       "      <td>-2.302989</td>\n",
       "      <td>-1.541601</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7209</td>\n",
       "      <td>김밥집 추억 돋는 노래들ㅎ 좋다</td>\n",
       "      <td>5.729249</td>\n",
       "      <td>-0.000913</td>\n",
       "      <td>-1.264938</td>\n",
       "      <td>-1.201638</td>\n",
       "      <td>-1.453974</td>\n",
       "      <td>-1.946835</td>\n",
       "      <td>-0.443806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33790</td>\n",
       "      <td>오늘 눈물이 나는 사건이 있었어</td>\n",
       "      <td>-0.260134</td>\n",
       "      <td>4.880246</td>\n",
       "      <td>0.593554</td>\n",
       "      <td>0.594296</td>\n",
       "      <td>-1.078087</td>\n",
       "      <td>-2.369928</td>\n",
       "      <td>-1.879972</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33506</td>\n",
       "      <td>예식 일정 때문에 웨딩홀 업체와 면담하고 왔어</td>\n",
       "      <td>1.205968</td>\n",
       "      <td>3.270586</td>\n",
       "      <td>2.222232</td>\n",
       "      <td>2.614387</td>\n",
       "      <td>-3.036747</td>\n",
       "      <td>-4.087882</td>\n",
       "      <td>-2.399920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>24892</td>\n",
       "      <td>성인 에이디에이치디 때문에 모든 일에 집중도 힘들어 가만히 있을 수가 없어</td>\n",
       "      <td>-0.703058</td>\n",
       "      <td>3.833485</td>\n",
       "      <td>2.834846</td>\n",
       "      <td>3.278788</td>\n",
       "      <td>-3.392626</td>\n",
       "      <td>-3.823911</td>\n",
       "      <td>-1.816149</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>38821</td>\n",
       "      <td>이국주도 콩밥먹여라</td>\n",
       "      <td>0.243841</td>\n",
       "      <td>-0.333419</td>\n",
       "      <td>2.554084</td>\n",
       "      <td>-0.994577</td>\n",
       "      <td>-3.873759</td>\n",
       "      <td>-3.274635</td>\n",
       "      <td>4.588078</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>8837</td>\n",
       "      <td>나두 좋은사람 만나구싶어 정말로 마음이 통하고 말이통하는 인생의 활력소 같은 터닝포...</td>\n",
       "      <td>5.556766</td>\n",
       "      <td>0.925507</td>\n",
       "      <td>-1.085666</td>\n",
       "      <td>-0.201743</td>\n",
       "      <td>-1.515639</td>\n",
       "      <td>-2.717503</td>\n",
       "      <td>-1.464471</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>43862</td>\n",
       "      <td>전염병에 걸려서 혼자 격리실에 있게 되었어</td>\n",
       "      <td>-0.768037</td>\n",
       "      <td>4.691122</td>\n",
       "      <td>2.358123</td>\n",
       "      <td>2.428739</td>\n",
       "      <td>-2.494840</td>\n",
       "      <td>-3.561412</td>\n",
       "      <td>-2.171278</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>12838</td>\n",
       "      <td>너 기다리다가 내 속도 새카맣게 다 탔어</td>\n",
       "      <td>2.510676</td>\n",
       "      <td>3.067337</td>\n",
       "      <td>1.805481</td>\n",
       "      <td>1.092347</td>\n",
       "      <td>-3.209166</td>\n",
       "      <td>-3.741423</td>\n",
       "      <td>-1.806883</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8771 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  text_pred_0  \\\n",
       "0     13873                          누나가 청소 내기를 하자고 했는데 내가 이겼어     5.299185   \n",
       "1     13586  노후 때문에 부동산 투기하던 친구가 이번에 세금을 많이 물게 됐다고 나한테 말했는데...    -1.710246   \n",
       "2      7209                                  김밥집 추억 돋는 노래들ㅎ 좋다     5.729249   \n",
       "3     33790                                  오늘 눈물이 나는 사건이 있었어    -0.260134   \n",
       "4     33506                          예식 일정 때문에 웨딩홀 업체와 면담하고 왔어     1.205968   \n",
       "...     ...                                                ...          ...   \n",
       "8766  24892          성인 에이디에이치디 때문에 모든 일에 집중도 힘들어 가만히 있을 수가 없어    -0.703058   \n",
       "8767  38821                                         이국주도 콩밥먹여라     0.243841   \n",
       "8768   8837  나두 좋은사람 만나구싶어 정말로 마음이 통하고 말이통하는 인생의 활력소 같은 터닝포...     5.556766   \n",
       "8769  43862                            전염병에 걸려서 혼자 격리실에 있게 되었어    -0.768037   \n",
       "8770  12838                             너 기다리다가 내 속도 새카맣게 다 탔어     2.510676   \n",
       "\n",
       "      text_pred_1  text_pred_2  text_pred_3  text_pred_4  text_pred_5  \\\n",
       "0        1.222584    -0.529279    -0.220333    -2.441689    -2.766117   \n",
       "1        4.793097     1.939720     0.995886    -1.486930    -2.302989   \n",
       "2       -0.000913    -1.264938    -1.201638    -1.453974    -1.946835   \n",
       "3        4.880246     0.593554     0.594296    -1.078087    -2.369928   \n",
       "4        3.270586     2.222232     2.614387    -3.036747    -4.087882   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8766     3.833485     2.834846     3.278788    -3.392626    -3.823911   \n",
       "8767    -0.333419     2.554084    -0.994577    -3.873759    -3.274635   \n",
       "8768     0.925507    -1.085666    -0.201743    -1.515639    -2.717503   \n",
       "8769     4.691122     2.358123     2.428739    -2.494840    -3.561412   \n",
       "8770     3.067337     1.805481     1.092347    -3.209166    -3.741423   \n",
       "\n",
       "      text_pred_6  label  pred  \n",
       "0       -1.144773      0     0  \n",
       "1       -1.541601      1     1  \n",
       "2       -0.443806      0     0  \n",
       "3       -1.879972      1     1  \n",
       "4       -2.399920      0     1  \n",
       "...           ...    ...   ...  \n",
       "8766    -1.816149      3     1  \n",
       "8767     4.588078      2     6  \n",
       "8768    -1.464471      0     0  \n",
       "8769    -2.171278      1     1  \n",
       "8770    -1.806883      2     1  \n",
       "\n",
       "[8771 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = evaluation(trainer = trainer,\n",
    "                eval_dataset = eval_dataset,\n",
    "                text_column_name = text_column)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9bddf2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:36.159269Z",
     "start_time": "2023-05-30T00:18:34.684364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>기쁨</th>\n",
       "      <th>우울</th>\n",
       "      <th>분노</th>\n",
       "      <th>두려움</th>\n",
       "      <th>사랑</th>\n",
       "      <th>놀람</th>\n",
       "      <th>중립</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13873</td>\n",
       "      <td>누나가 청소 내기를 하자고 했는데 내가 이겼어</td>\n",
       "      <td>0.974417</td>\n",
       "      <td>0.016531</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.000424</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13586</td>\n",
       "      <td>노후 때문에 부동산 투기하던 친구가 이번에 세금을 많이 물게 됐다고 나한테 말했는데...</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.920763</td>\n",
       "      <td>0.053081</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>우울</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7209</td>\n",
       "      <td>김밥집 추억 돋는 노래들ㅎ 좋다</td>\n",
       "      <td>0.991622</td>\n",
       "      <td>0.003219</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000969</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33790</td>\n",
       "      <td>오늘 눈물이 나는 사건이 있었어</td>\n",
       "      <td>0.005642</td>\n",
       "      <td>0.963559</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.002490</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>우울</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33506</td>\n",
       "      <td>예식 일정 때문에 웨딩홀 업체와 면담하고 왔어</td>\n",
       "      <td>0.063367</td>\n",
       "      <td>0.499474</td>\n",
       "      <td>0.175073</td>\n",
       "      <td>0.259137</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8766</th>\n",
       "      <td>24892</td>\n",
       "      <td>성인 에이디에이치디 때문에 모든 일에 집중도 힘들어 가만히 있을 수가 없어</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.510711</td>\n",
       "      <td>0.188136</td>\n",
       "      <td>0.293274</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.001797</td>\n",
       "      <td>두려움</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8767</th>\n",
       "      <td>38821</td>\n",
       "      <td>이국주도 콩밥먹여라</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.113214</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>분노</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8768</th>\n",
       "      <td>8837</td>\n",
       "      <td>나두 좋은사람 만나구싶어 정말로 마음이 통하고 말이통하는 인생의 활력소 같은 터닝포...</td>\n",
       "      <td>0.984060</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.003106</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8769</th>\n",
       "      <td>43862</td>\n",
       "      <td>전염병에 걸려서 혼자 격리실에 있게 되었어</td>\n",
       "      <td>0.003526</td>\n",
       "      <td>0.828207</td>\n",
       "      <td>0.080340</td>\n",
       "      <td>0.086218</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>우울</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8770</th>\n",
       "      <td>12838</td>\n",
       "      <td>너 기다리다가 내 속도 새카맣게 다 탔어</td>\n",
       "      <td>0.285755</td>\n",
       "      <td>0.498595</td>\n",
       "      <td>0.141166</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.003810</td>\n",
       "      <td>분노</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8771 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text        기쁨  \\\n",
       "0     13873                          누나가 청소 내기를 하자고 했는데 내가 이겼어  0.974417   \n",
       "1     13586  노후 때문에 부동산 투기하던 친구가 이번에 세금을 많이 물게 됐다고 나한테 말했는데...  0.001380   \n",
       "2      7209                                  김밥집 추억 돋는 노래들ㅎ 좋다  0.991622   \n",
       "3     33790                                  오늘 눈물이 나는 사건이 있었어  0.005642   \n",
       "4     33506                          예식 일정 때문에 웨딩홀 업체와 면담하고 왔어  0.063367   \n",
       "...     ...                                                ...       ...   \n",
       "8766  24892          성인 에이디에이치디 때문에 모든 일에 집중도 힘들어 가만히 있을 수가 없어  0.005470   \n",
       "8767  38821                                         이국주도 콩밥먹여라  0.011235   \n",
       "8768   8837  나두 좋은사람 만나구싶어 정말로 마음이 통하고 말이통하는 인생의 활력소 같은 터닝포...  0.984060   \n",
       "8769  43862                            전염병에 걸려서 혼자 격리실에 있게 되었어  0.003526   \n",
       "8770  12838                             너 기다리다가 내 속도 새카맣게 다 탔어  0.285755   \n",
       "\n",
       "            우울        분노       두려움        사랑        놀람        중립 label pred  \n",
       "0     0.016531  0.002867  0.003905  0.000424  0.000306  0.001549    기쁨   기쁨  \n",
       "1     0.920763  0.053081  0.020656  0.001725  0.000763  0.001633    우울   우울  \n",
       "2     0.003219  0.000910  0.000969  0.000753  0.000460  0.002067    기쁨   기쁨  \n",
       "3     0.963559  0.013249  0.013259  0.002490  0.000684  0.001117    우울   우울  \n",
       "4     0.499474  0.175073  0.259137  0.000910  0.000318  0.001721    기쁨   우울  \n",
       "...        ...       ...       ...       ...       ...       ...   ...  ...  \n",
       "8766  0.510711  0.188136  0.293274  0.000371  0.000241  0.001797   두려움   우울  \n",
       "8767  0.006308  0.113214  0.003256  0.000183  0.000333  0.865471    분노   중립  \n",
       "8768  0.009587  0.001283  0.003106  0.000835  0.000251  0.000878    기쁨   기쁨  \n",
       "8769  0.828207  0.080340  0.086218  0.000627  0.000216  0.000867    우울   우울  \n",
       "8770  0.498595  0.141166  0.069186  0.000937  0.000550  0.003810    분노   우울  \n",
       "\n",
       "[8771 rows x 11 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = df.copy()\n",
    "result_df.columns = [\"id\", \"text\", \"기쁨\", \"우울\", '분노', '두려움', '사랑', '놀람', '중립', 'label', 'pred']\n",
    "\n",
    "def softmax(row):\n",
    "    e = np.exp(row) \n",
    "    return e / e.sum()\n",
    "\n",
    "cols = [\"기쁨\", \"우울\", '분노', '두려움', '사랑', '놀람', '중립']\n",
    "result_df[cols] = result_df[cols].apply(softmax, axis=1)\n",
    "\n",
    "result_df['label'] = result_df['label'].replace([0,1,2,3,4,5,6], ['기쁨', '우울', '분노', '두려움', '사랑', '놀람', '중립'])\n",
    "result_df['pred'] = result_df['pred'].replace([0,1,2,3,4,5,6], ['기쁨', '우울', '분노', '두려움', '사랑', '놀람', '중립'])\n",
    "\n",
    "result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24a5b6f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:36.167679Z",
     "start_time": "2023-05-30T00:18:36.160091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>기쁨</th>\n",
       "      <th>우울</th>\n",
       "      <th>분노</th>\n",
       "      <th>두려움</th>\n",
       "      <th>사랑</th>\n",
       "      <th>놀람</th>\n",
       "      <th>중립</th>\n",
       "      <th>label</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7682</th>\n",
       "      <td>27691</td>\n",
       "      <td>아내랑 딸에게 혹시 모르니 건강 검진을 받으러 가자고 했어 다들 어서 검사를 받아봐...</td>\n",
       "      <td>0.022908</td>\n",
       "      <td>0.174268</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>0.764352</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>분노</td>\n",
       "      <td>두려움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>48744</td>\n",
       "      <td>체질상 땀이 많은데 여름의 시작이ㅜㅜ</td>\n",
       "      <td>0.784991</td>\n",
       "      <td>0.172547</td>\n",
       "      <td>0.013307</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>우울</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3404</th>\n",
       "      <td>35227</td>\n",
       "      <td>완전 잘 어울려ㅜㅜㅜㅜㅜㅜㅜ믿고 봅니다</td>\n",
       "      <td>0.988272</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6522</th>\n",
       "      <td>18413</td>\n",
       "      <td>망할 예산안 언제쓰지</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.011226</td>\n",
       "      <td>0.516768</td>\n",
       "      <td>0.017819</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.451371</td>\n",
       "      <td>우울</td>\n",
       "      <td>분노</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4664</th>\n",
       "      <td>46705</td>\n",
       "      <td>지난 달에 아우가 건강검진을 받았다고 해서 걱정했는데 결과를 보니 다행이야</td>\n",
       "      <td>0.990549</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>22090</td>\n",
       "      <td>보니까 저도 하고 싶어서하는게 좋을까요</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.140638</td>\n",
       "      <td>0.009341</td>\n",
       "      <td>0.841904</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>두려움</td>\n",
       "      <td>두려움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>51112</td>\n",
       "      <td>트럼프면 중국이 공조 안하면 같이 조짐</td>\n",
       "      <td>0.002850</td>\n",
       "      <td>0.003023</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>0.103024</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.858149</td>\n",
       "      <td>중립</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>26992</td>\n",
       "      <td>십팔세이상 담배 술은</td>\n",
       "      <td>0.012601</td>\n",
       "      <td>0.012986</td>\n",
       "      <td>0.209316</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.760201</td>\n",
       "      <td>중립</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3543</th>\n",
       "      <td>27378</td>\n",
       "      <td>아기가 곧 태어나는데 양육을 위해 필요한 물품을 마련할 능력이 안 되는 내가 너무 한심해</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.643079</td>\n",
       "      <td>0.162192</td>\n",
       "      <td>0.189764</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>우울</td>\n",
       "      <td>우울</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3783</th>\n",
       "      <td>9346</td>\n",
       "      <td>나의 절친한 친구가 축의금을 엄청 많이 내주어서 기뻐</td>\n",
       "      <td>0.990269</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.001008</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>기쁨</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text        기쁨  \\\n",
       "7682  27691  아내랑 딸에게 혹시 모르니 건강 검진을 받으러 가자고 했어 다들 어서 검사를 받아봐...  0.022908   \n",
       "1022  48744                               체질상 땀이 많은데 여름의 시작이ㅜㅜ  0.784991   \n",
       "3404  35227                              완전 잘 어울려ㅜㅜㅜㅜㅜㅜㅜ믿고 봅니다  0.988272   \n",
       "6522  18413                                        망할 예산안 언제쓰지  0.001863   \n",
       "4664  46705          지난 달에 아우가 건강검진을 받았다고 해서 걱정했는데 결과를 보니 다행이야  0.990549   \n",
       "2029  22090                              보니까 저도 하고 싶어서하는게 좋을까요  0.006528   \n",
       "2002  51112                              트럼프면 중국이 공조 안하면 같이 조짐  0.002850   \n",
       "7998  26992                                        십팔세이상 담배 술은  0.012601   \n",
       "3543  27378  아기가 곧 태어나는데 양육을 위해 필요한 물품을 마련할 능력이 안 되는 내가 너무 한심해  0.002589   \n",
       "3783   9346                      나의 절친한 친구가 축의금을 엄청 많이 내주어서 기뻐  0.990269   \n",
       "\n",
       "            우울        분노       두려움        사랑        놀람        중립 label pred  \n",
       "7682  0.174268  0.036600  0.764352  0.000475  0.000421  0.000977    분노  두려움  \n",
       "1022  0.172547  0.013307  0.022286  0.000395  0.000501  0.005974    우울   기쁨  \n",
       "3404  0.005686  0.000816  0.002469  0.000384  0.000315  0.002059    기쁨   기쁨  \n",
       "6522  0.011226  0.516768  0.017819  0.000369  0.000584  0.451371    우울   분노  \n",
       "4664  0.004501  0.000835  0.002005  0.000606  0.000325  0.001179    기쁨   기쁨  \n",
       "2029  0.140638  0.009341  0.841904  0.000391  0.000516  0.000681   두려움  두려움  \n",
       "2002  0.003023  0.024944  0.103024  0.000447  0.007563  0.858149    중립   중립  \n",
       "7998  0.012986  0.209316  0.004311  0.000235  0.000350  0.760201    중립   중립  \n",
       "3543  0.643079  0.162192  0.189764  0.001088  0.000342  0.000946    우울   우울  \n",
       "3783  0.004816  0.001008  0.001728  0.000674  0.000299  0.001205    기쁨   기쁨  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7649d7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:36.186080Z",
     "start_time": "2023-05-30T00:18:36.168303Z"
    }
   },
   "outputs": [],
   "source": [
    "# # 나눔글꼴 설치\n",
    "# !apt-get install -y fonts-nanum\n",
    "# # matplotlib에 남아있는 폰트 캐시 삭제\n",
    "# !rm -rf ~/.cache/matplotlib/*\n",
    "# !fc-cache -fv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9624b720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:36.197057Z",
     "start_time": "2023-05-30T00:18:36.187012Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 유니코드 깨짐현상 해결\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 나눔고딕 폰트 적용\n",
    "plt.rcParams[\"font.family\"] = 'NanumGothic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64e9fb1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:45:00.860842Z",
     "start_time": "2023-05-30T00:45:00.802174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_index = 102\n",
    "\n",
    "# Select the row (for example, the first row)\n",
    "row = result_df.loc[text_index, cols]\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "plt.figure(figsize=(10, 5))  # Set the figure size\n",
    "plt.barh(cols, row, color='skyblue')  # Create a horizontal bar plot\n",
    "plt.xlabel('Percentage')  # Set the x-label\n",
    "plt.title('Prediction Percentages for Text 0')  # Set the title\n",
    "plt.show()  # Display the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17639084",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:45:37.280249Z",
     "start_time": "2023-05-30T00:45:37.273301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "기쁨     0.858965\n",
       "우울     0.100959\n",
       "분노     0.007807\n",
       "두려움    0.027251\n",
       "사랑     0.000311\n",
       "놀람      0.00036\n",
       "중립     0.004348\n",
       "Name: 102, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47c9ba6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-30T00:18:36.285651Z",
     "start_time": "2023-05-30T00:18:36.273096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1202  132   34   28    3    3   89]\n",
      " [ 193 2015  204  363    1    1   53]\n",
      " [  97  426 1263  125    0    1  281]\n",
      " [  77  390  124  849    0    0   99]\n",
      " [   6    1    0    0    0    0    0]\n",
      " [   5    2    0    0    0    1    1]\n",
      " [ 110   63  146   48    0    3  332]]\n",
      "-------------------------\n",
      "Accuracy: 0.6455364268612472\n",
      "F1 score: 0.6449019647823618\n",
      "Recall: 0.6455364268612472\n",
      "Precision: 0.650476482979754\n"
     ]
    }
   ],
   "source": [
    "# Check the classification result of each XLM-RoBERTa Model \n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, \n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score\n",
    ")\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(df.label, df.pred))\n",
    "print(\"-------------------------\")\n",
    "accuracy = accuracy_score(df.label, df.pred)\n",
    "f1 = f1_score(df.label, df.pred, average='weighted')\n",
    "recall = recall_score(df.label, df.pred, average='weighted')\n",
    "precision = precision_score(df.label, df.pred, average='weighted')\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 score: {f1}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"Precision: {precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1ae186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
